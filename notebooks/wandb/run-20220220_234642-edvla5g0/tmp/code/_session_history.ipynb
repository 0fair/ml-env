{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83804ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export AWS_S3_ENDPOINT_URL=http://localhost:8000\n",
    "!export AWS_ACCESS_KEY_ID=DevAccessKey\n",
    "!export AWS_SECRET_ACCESS_KEY=DevSecretKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed098f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key='local-8c4310dcf3cb371cac7343a466e09de6b04e4282', host='http://localhost:8080')\n",
    "ENTITY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21477f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from dill.source import getsource\n",
    "from dill import detect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3b4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/')\n",
    "model_dir = Path('../models')\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "id_vars = ['UniqueID']\n",
    "targ_var = 'loan_default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17e1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_string(fn):\n",
    "    return getsource(detect.code(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d1ef354",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=ENTITY, name=\"score1\", project='credit_scorecard', job_type='preprocess-data', config={'wandb_nb':'wandb_credit_soc'})  # config is optional here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784802bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import (\n",
    "    describe_data_g_targ,\n",
    "    one_hot_encode_data,\n",
    "    create_feature_interaction_constraints,\n",
    "    get_monotonic_constraints,\n",
    "    load_training_data,\n",
    "    calculate_credit_scores\n",
    ")\n",
    "\n",
    "from src.scorecard import generate_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bcecdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UniqueID    LTV  manufacturer_id Employment_Type  State_ID  \\\n",
      "0    417428  88.17               86   Self employed         4   \n",
      "1    417429  83.78               86        Salaried         8   \n",
      "2    417430  77.39               86   Self employed         6   \n",
      "3    417431  72.14               86   Self employed         3   \n",
      "4    417432  85.92               86   Self employed         6   \n",
      "\n",
      "   PERFORM_CNS_SCORE  AgeInMonths  DaysSinceDisbursement  loan_default  \n",
      "0              681.0        638.0                  153.0             0  \n",
      "1              384.0        478.0                  153.0             0  \n",
      "2                NaN        441.0                  153.0             0  \n",
      "3                NaN        384.0                  153.0             0  \n",
      "4              721.0        343.0                  153.0             0  "
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(data_dir/'vehicle_loans_subset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72403944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, p_vars = one_hot_encode_data(dataset, id_vars, targ_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b779eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = data_dir/'proc_ds.csv'\n",
    "dataset.to_csv(processed_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10128de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e84320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from dill.source import getsource\n",
    "from dill import detect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aeeff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from dill.source import getsource\n",
    "from dill import detect\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d576b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_S3_ENDPOINT_URL\"] = \"http://localhost:8000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"DevAccessKey\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"DevSecretKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae55a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]"
     ]
    }
   ],
   "source": [
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7938d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ManifestEntry digest: cslJubeoq5UrWhqw3sBeqw==>"
     ]
    }
   ],
   "source": [
    "# Attach our processed data to the Artifact\n",
    "processed_ds_art.add_file(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "672b197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(processed_ds_art)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97cd71b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]"
     ]
    }
   ],
   "source": [
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f89e364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ManifestEntry digest: cslJubeoq5UrWhqw3sBeqw==>"
     ]
    }
   ],
   "source": [
    "# Attach our processed data to the Artifact\n",
    "processed_ds_art.add_file(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "596fe083",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(processed_ds_art)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb492d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=ENTITY, name=\"score1\", project='credit_scorecard', job_type='preprocess-data', config={'wandb_nb':'wandb_credit_soc'})  # config is optional here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe28c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import (\n",
    "    describe_data_g_targ,\n",
    "    one_hot_encode_data,\n",
    "    create_feature_interaction_constraints,\n",
    "    get_monotonic_constraints,\n",
    "    load_training_data,\n",
    "    calculate_credit_scores\n",
    ")\n",
    "\n",
    "from src.scorecard import generate_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e145114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UniqueID    LTV  manufacturer_id Employment_Type  State_ID  \\\n",
      "0    417428  88.17               86   Self employed         4   \n",
      "1    417429  83.78               86        Salaried         8   \n",
      "2    417430  77.39               86   Self employed         6   \n",
      "3    417431  72.14               86   Self employed         3   \n",
      "4    417432  85.92               86   Self employed         6   \n",
      "\n",
      "   PERFORM_CNS_SCORE  AgeInMonths  DaysSinceDisbursement  loan_default  \n",
      "0              681.0        638.0                  153.0             0  \n",
      "1              384.0        478.0                  153.0             0  \n",
      "2                NaN        441.0                  153.0             0  \n",
      "3                NaN        384.0                  153.0             0  \n",
      "4              721.0        343.0                  153.0             0  "
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(data_dir/'vehicle_loans_subset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f6ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, p_vars = one_hot_encode_data(dataset, id_vars, targ_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddb0b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = data_dir/'proc_ds.csv'\n",
    "dataset.to_csv(processed_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ed90705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]"
     ]
    }
   ],
   "source": [
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fce9a278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ManifestEntry digest: cslJubeoq5UrWhqw3sBeqw==>"
     ]
    }
   ],
   "source": [
    "# Attach our processed data to the Artifact\n",
    "processed_ds_art.add_file(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15763784",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(processed_ds_art)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efbd3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=ENTITY, name=\"score2\", project='credit_scorecard', job_type='preprocess-data', config={'wandb_nb':'wandb_credit_soc'})  # config is optional here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f0aabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import (\n",
    "    describe_data_g_targ,\n",
    "    one_hot_encode_data,\n",
    "    create_feature_interaction_constraints,\n",
    "    get_monotonic_constraints,\n",
    "    load_training_data,\n",
    "    calculate_credit_scores\n",
    ")\n",
    "\n",
    "from src.scorecard import generate_scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a6dfd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UniqueID    LTV  manufacturer_id Employment_Type  State_ID  \\\n",
      "0    417428  88.17               86   Self employed         4   \n",
      "1    417429  83.78               86        Salaried         8   \n",
      "2    417430  77.39               86   Self employed         6   \n",
      "3    417431  72.14               86   Self employed         3   \n",
      "4    417432  85.92               86   Self employed         6   \n",
      "\n",
      "   PERFORM_CNS_SCORE  AgeInMonths  DaysSinceDisbursement  loan_default  \n",
      "0              681.0        638.0                  153.0             0  \n",
      "1              384.0        478.0                  153.0             0  \n",
      "2                NaN        441.0                  153.0             0  \n",
      "3                NaN        384.0                  153.0             0  \n",
      "4              721.0        343.0                  153.0             0  "
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(data_dir/'vehicle_loans_subset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "219ed4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, p_vars = one_hot_encode_data(dataset, id_vars, targ_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0705a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = data_dir/'proc_ds.csv'\n",
    "dataset.to_csv(processed_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25d043f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file('proc_ds.csv', 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ded35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file(data_dir/'proc_ds.csv', 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3b0dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file(data_dir/'proc_ds.csv', 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "452b9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7861867",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(data_dir/'proc_ds.csv', 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22d8cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file(data_dir + '/proc_ds.csv', 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56cd032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv'.__str__()), 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef664da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__()), 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06c55921",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d539daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_S3_ENDPOINT_URL\"] = \"http://localhost:8000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"DevAccessKey\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"DevSecretKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43fd80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed')\n",
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5079680",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6481f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00716281",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_S3_ENDPOINT_URL\"] = \"http://localhost:8000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"DevAccessKeym\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"DevSecretKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84455a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73fc7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3', endpoint_url=\"http://localhost:8000\",\n",
    "                         aws_access_key_id=\"DevAccessKey\", aws_secret_access_key=\"DevSecretKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "02a241ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "301f9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a60b8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file((data_dir/'proc_ds.csv').__str__(), 'creditscore', 'datasets/vehicle_defaults_processed1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0f8268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbbcfff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_S3_ENDPOINT_URL\"] = \"http://localhost:8000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"DevAccessKey\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"DevSecretKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "478ecd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ManifestEntry ref: s3://creditscore/datasets/vehicle_defaults_processed/vehicle_defaults_processed>]"
     ]
    }
   ],
   "source": [
    "\n",
    "processed_ds_art = wandb.Artifact(name='vehicle_defaults_processed',\n",
    "                                  type='processed_dataset',\n",
    "                                  description='One-hot encoded dataset',\n",
    "                                  metadata={'preprocessing_fn': function_to_string(one_hot_encode_data)}\n",
    "                                  )\n",
    "processed_ds_art.add_reference('s3://creditscore/datasets/vehicle_defaults_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb371259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ManifestEntry digest: cslJubeoq5UrWhqw3sBeqw==>"
     ]
    }
   ],
   "source": [
    "# Attach our processed data to the Artifact\n",
    "processed_ds_art.add_file(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8256bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_artifact(processed_ds_art)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42877d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(entity=ENTITY, name=\"model1\", project='credit_scorecard', job_type='train-val-split', config={'wandb_nb':'wandb_credit_soc'}) as run:     # config is optional here\n",
    "\n",
    "    # Download the subset of the vehicle loan default data from W&B\n",
    "    dataset_art = run.use_artifact('vehicle_defaults_processed:latest', type='processed_dataset')\n",
    "    dataset_dir = dataset_art.download(data_dir)\n",
    "    dataset = pd.read_csv(processed_data_path)\n",
    "\n",
    "    # Set Split Params\n",
    "    test_size = 0.25\n",
    "    random_state = 42\n",
    "\n",
    "    # Log the splilt params\n",
    "    run.config.update({'test_size':test_size, 'random_state': random_state})\n",
    "\n",
    "    # Do the Train/Val Split\n",
    "    trndat, valdat = model_selection.train_test_split(dataset, test_size=test_size,\n",
    "                                                      random_state=random_state, stratify=dataset[[targ_var]])\n",
    "\n",
    "    print(f'Train dataset size: {trndat[targ_var].value_counts()} \\n')\n",
    "    print(f'Validation dataset sizeL {valdat[targ_var].value_counts()}')\n",
    "\n",
    "    # Save split datasets\n",
    "    train_path = data_dir/'train.csv'\n",
    "    val_path = data_dir/'val.csv'\n",
    "    trndat.to_csv(train_path, index=False)\n",
    "    valdat.to_csv(val_path, index=False)\n",
    "\n",
    "\n",
    "    # Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
    "    split_ds_art = wandb.Artifact(name='vehicle_defaults_split',\n",
    "                                  type='train-val-dataset',\n",
    "                                  description='Processed dataset split into train and valiation',\n",
    "                                  metadata={'test_size': test_size, 'random_state': random_state}\n",
    "                                  )\n",
    "    split_ds_art.add_reference('s3://creditscore/artefacts')\n",
    "\n",
    "    # Attach our processed data to the Artifact\n",
    "    split_ds_art.add_file(train_path)\n",
    "    split_ds_art.add_file(val_path)\n",
    "\n",
    "    # Log the Artifact\n",
    "    run.log_artifact(split_ds_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be99ffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(entity=ENTITY, name=\"split2\", project='credit_scorecard', job_type='train-val-split', config={'wandb_nb':'wandb_credit_soc'}) as run:     # config is optional here\n",
    "\n",
    "    # Download the subset of the vehicle loan default data from W&B\n",
    "    dataset_art = run.use_artifact('vehicle_defaults_processed:latest', type='processed_dataset')\n",
    "    dataset_dir = dataset_art.download(data_dir)\n",
    "    dataset = pd.read_csv(processed_data_path)\n",
    "\n",
    "    # Set Split Params\n",
    "    test_size = 0.25\n",
    "    random_state = 42\n",
    "\n",
    "    # Log the splilt params\n",
    "    run.config.update({'test_size':test_size, 'random_state': random_state})\n",
    "\n",
    "    # Do the Train/Val Split\n",
    "    trndat, valdat = model_selection.train_test_split(dataset, test_size=test_size,\n",
    "                                                      random_state=random_state, stratify=dataset[[targ_var]])\n",
    "\n",
    "    print(f'Train dataset size: {trndat[targ_var].value_counts()} \\n')\n",
    "    print(f'Validation dataset sizeL {valdat[targ_var].value_counts()}')\n",
    "\n",
    "    # Save split datasets\n",
    "    train_path = data_dir/'train.csv'\n",
    "    val_path = data_dir/'val.csv'\n",
    "    trndat.to_csv(train_path, index=False)\n",
    "    valdat.to_csv(val_path, index=False)\n",
    "\n",
    "    s3_client.upload_file(train_path.__str__(), 'creditscore', 'artifacts/train.csv')\n",
    "    s3_client.upload_file(val_path.__str__(), 'creditscore', 'artifacts/val.csv')\n",
    "\n",
    "    # Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
    "    split_ds_art = wandb.Artifact(name='vehicle_defaults_split',\n",
    "                                  type='train-val-dataset',\n",
    "                                  description='Processed dataset split into train and valiation',\n",
    "                                  metadata={'test_size': test_size, 'random_state': random_state}\n",
    "                                  )\n",
    "    split_ds_art.add_reference('s3://creditscore/artifacts')\n",
    "\n",
    "    # Attach our processed data to the Artifact\n",
    "    # split_ds_art.add_file('train.csv')\n",
    "    # split_ds_art.add_file('val.csv')\n",
    "\n",
    "    # Log the Artifact\n",
    "    run.log_artifact(split_ds_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94fa5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(entity=ENTITY, name=\"split3\", project='credit_scorecard', job_type='train-val-split', config={'wandb_nb':'wandb_credit_soc'}) as run:     # config is optional here\n",
    "\n",
    "    # Download the subset of the vehicle loan default data from W&B\n",
    "    dataset_art = run.use_artifact('vehicle_defaults_processed:latest', type='processed_dataset')\n",
    "    dataset_dir = dataset_art.download(data_dir)\n",
    "    dataset = pd.read_csv(processed_data_path)\n",
    "\n",
    "    # Set Split Params\n",
    "    test_size = 0.25\n",
    "    random_state = 42\n",
    "\n",
    "    # Log the splilt params\n",
    "    run.config.update({'test_size':test_size, 'random_state': random_state})\n",
    "\n",
    "    # Do the Train/Val Split\n",
    "    trndat, valdat = model_selection.train_test_split(dataset, test_size=test_size,\n",
    "                                                      random_state=random_state, stratify=dataset[[targ_var]])\n",
    "\n",
    "    print(f'Train dataset size: {trndat[targ_var].value_counts()} \\n')\n",
    "    print(f'Validation dataset sizeL {valdat[targ_var].value_counts()}')\n",
    "\n",
    "    # Save split datasets\n",
    "    train_path = data_dir/'train.csv'\n",
    "    val_path = data_dir/'val.csv'\n",
    "    trndat.to_csv(train_path, index=False)\n",
    "    valdat.to_csv(val_path, index=False)\n",
    "\n",
    "    s3_client.upload_file(train_path.__str__(), 'creditscore', 'artifacts/train.csv')\n",
    "    s3_client.upload_file(val_path.__str__(), 'creditscore', 'artifacts/val.csv')\n",
    "\n",
    "    # Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
    "    split_ds_art = wandb.Artifact(name='vehicle_defaults_split',\n",
    "                                  type='train-val-dataset',\n",
    "                                  description='Processed dataset split into train and valiation',\n",
    "                                  metadata={'test_size': test_size, 'random_state': random_state}\n",
    "                                  )\n",
    "    split_ds_art.add_reference('http://localhost:8001/creditscore/artifacts')\n",
    "\n",
    "    # Attach our processed data to the Artifact\n",
    "    # split_ds_art.add_file('train.csv')\n",
    "    # split_ds_art.add_file('val.csv')\n",
    "\n",
    "    # Log the Artifact\n",
    "    run.log_artifact(split_ds_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44e05b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"http://localhost:8080/den/credit_scorecard/runs/edvla5g0\" target=\"_blank\">split4</a></strong> to <a href=\"http://localhost:8080/den/credit_scorecard\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(entity=ENTITY, name=\"split4\", project='credit_scorecard', job_type='train-val-split', config={'wandb_nb':'wandb_credit_soc'}) as run:     # config is optional here\n",
    "\n",
    "    # Download the subset of the vehicle loan default data from W&B\n",
    "    dataset_art = run.use_artifact('vehicle_defaults_processed:latest', type='processed_dataset')\n",
    "    dataset_dir = dataset_art.download(data_dir)\n",
    "    dataset = pd.read_csv(processed_data_path)\n",
    "\n",
    "    # Set Split Params\n",
    "    test_size = 0.25\n",
    "    random_state = 42\n",
    "\n",
    "    # Log the splilt params\n",
    "    run.config.update({'test_size':test_size, 'random_state': random_state})\n",
    "\n",
    "    # Do the Train/Val Split\n",
    "    trndat, valdat = model_selection.train_test_split(dataset, test_size=test_size,\n",
    "                                                      random_state=random_state, stratify=dataset[[targ_var]])\n",
    "\n",
    "    print(f'Train dataset size: {trndat[targ_var].value_counts()} \\n')\n",
    "    print(f'Validation dataset sizeL {valdat[targ_var].value_counts()}')\n",
    "\n",
    "    # Save split datasets\n",
    "    train_path = data_dir/'train.csv'\n",
    "    val_path = data_dir/'val.csv'\n",
    "    trndat.to_csv(train_path, index=False)\n",
    "    valdat.to_csv(val_path, index=False)\n",
    "\n",
    "    s3_client.upload_file(train_path.__str__(), 'creditscore', 'artifacts/train.csv')\n",
    "    s3_client.upload_file(val_path.__str__(), 'creditscore', 'artifacts/val.csv')\n",
    "\n",
    "    # Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
    "    split_ds_art = wandb.Artifact(name='vehicle_defaults_split',\n",
    "                                  type='train-val-dataset',\n",
    "                                  description='Processed dataset split into train and valiation',\n",
    "                                  metadata={'test_size': test_size, 'random_state': random_state}\n",
    "                                  )\n",
    "    split_ds_art.add_reference('s3://creditscore/artifacts')\n",
    "\n",
    "    # Attach our processed data to the Artifact\n",
    "    split_ds_art.add_file('train.csv')\n",
    "    split_ds_art.add_file('val.csv')\n",
    "\n",
    "    # Log the Artifact\n",
    "    run.log_artifact(split_ds_art)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
